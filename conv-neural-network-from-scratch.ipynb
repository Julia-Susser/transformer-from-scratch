{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8f823e5-266d-4f68-8efb-e1715b1c4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torchvision.datasets import *\n",
    "from torch.optim import *\n",
    "from torchvision.transforms import *\n",
    "from collections import OrderedDict, defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train = CIFAR10(\n",
    "    root=\"../cifar10/cifar10\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=Compose([\n",
    "    RandomCrop(32, padding=4),\n",
    "    RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "  ]),\n",
    "  )\n",
    "\n",
    "test = CIFAR10(\n",
    "    root=\"../cifar10/cifar10\",\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=ToTensor()\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a685b30e-cd29-4c85-a4a0-e70270a0514a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = test[0]\n",
    "plt.figure(figsize=(2, 2))\n",
    "image = image.permute(1, 2, 0)\n",
    "\n",
    "label = test.classes[label]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.title(label)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46cb6f4-a4c3-4ece-914e-b7211c617321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://arxiv.org/abs/1409.1556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ece8d1a1-dc0f-4a83-82e9-e484ad8d6424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ARCH = [64, 128, 'POOL', 256, 256, 'POOL', 512, 512, 'POOL', 512, 512, 'POOL'] #ARCH is autoregressive (predict future based on past) conditional heteroskedasticity\n",
    "        #co is out channels, ci is in channels\n",
    "        ci = 3 #RGB\n",
    "        layers = []\n",
    "        for x,co in enumerate(ARCH):\n",
    "            if co != \"POOL\":\n",
    "                layers.append((\"conv\"+str(x), nn.Conv2d(ci, co, 3, padding=1, bias=False))) #3 is kernel size kh=kw\n",
    "                layers.append((\"batch\"+str(x),nn.BatchNorm2d(co)))\n",
    "                layers.append((\"relu\"+str(x),nn.ReLU(True)))\n",
    "                \n",
    "                ci = co\n",
    "            else:\n",
    "                layers.append((\"pool\"+str(x),nn.MaxPool2d(2))) #max out of 2 by 2 so dim size goes down by half on width and height\n",
    "                #number of channels and features doesn't change\n",
    "        self.seq = nn.Sequential(OrderedDict(layers))\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "    def forward(self,x):\n",
    "        x = self.seq(x)\n",
    "        #avg pool\n",
    "        x = x.mean([2,3]) #N, 512, 2 x 2 => N 512 by finding average\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = VGG()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6791bdf-0cef-4e40-8e5e-b62af7737900",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "  )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test,\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0383e3e-62db-4d32-b588-02e8f73ee020",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(\n",
    "  model.parameters(),\n",
    "  lr=0.4,\n",
    "  momentum=0.9,\n",
    "  weight_decay=5e-4,\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89350176-66bb-4c64-aff9-05cf892a6be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0a807939c64dc3a472514157699b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 0:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(2.3205, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1094)\n",
      "loss tensor(2.3073, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1094)\n",
      "loss tensor(2.3590, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1055)\n",
      "loss tensor(2.3275, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1152)\n",
      "loss tensor(2.2990, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1172)\n",
      "loss tensor(2.2931, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1094)\n",
      "loss tensor(2.3089, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1016)\n",
      "loss tensor(2.2919, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1074)\n",
      "loss tensor(2.2992, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0781)\n",
      "loss tensor(2.2799, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1113)\n",
      "loss tensor(2.3085, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1250)\n",
      "loss tensor(2.3238, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1133)\n",
      "loss tensor(2.3264, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1055)\n",
      "loss tensor(2.2965, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0840)\n",
      "loss tensor(2.2873, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1172)\n",
      "loss tensor(2.2980, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1191)\n",
      "loss tensor(2.3119, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1016)\n",
      "loss tensor(2.2877, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1250)\n",
      "loss tensor(2.3223, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1113)\n",
      "loss tensor(2.2942, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1094)\n",
      "loss tensor(2.2862, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1387)\n",
      "loss tensor(2.2898, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1074)\n",
      "loss tensor(2.2954, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0977)\n",
      "loss tensor(2.2895, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1133)\n",
      "loss tensor(2.3019, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1094)\n",
      "loss tensor(2.3031, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1016)\n",
      "loss tensor(2.2935, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1035)\n",
      "loss tensor(2.2951, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1270)\n",
      "loss tensor(2.2967, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1289)\n",
      "loss tensor(2.2907, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1016)\n",
      "loss tensor(2.2843, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1152)\n",
      "loss tensor(2.2819, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1523)\n",
      "loss tensor(2.3070, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1191)\n",
      "loss tensor(2.3105, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1094)\n",
      "loss tensor(2.2969, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0996)\n",
      "loss tensor(2.2843, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1191)\n",
      "loss tensor(2.2819, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1074)\n",
      "loss tensor(2.2892, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0938)\n",
      "loss tensor(2.2894, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1270)\n",
      "loss tensor(2.2917, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1172)\n",
      "loss tensor(2.2806, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1289)\n",
      "loss tensor(2.2942, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1250)\n",
      "loss tensor(2.3152, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0918)\n",
      "loss tensor(2.2834, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1016)\n",
      "loss tensor(2.2809, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1230)\n",
      "loss tensor(2.2794, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1055)\n",
      "loss tensor(2.2691, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1016)\n",
      "loss tensor(2.2739, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0879)\n",
      "loss tensor(2.2925, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1191)\n",
      "loss tensor(2.2621, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1426)\n",
      "loss tensor(2.2728, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1074)\n",
      "loss tensor(2.2729, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1328)\n",
      "loss tensor(2.2911, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1152)\n",
      "loss tensor(2.2945, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0938)\n",
      "loss tensor(2.2818, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1230)\n",
      "loss tensor(2.2850, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1133)\n",
      "loss tensor(2.2907, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1016)\n",
      "loss tensor(2.2695, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1270)\n",
      "loss tensor(2.2803, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1152)\n",
      "loss tensor(2.2957, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1094)\n",
      "loss tensor(2.2782, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1211)\n",
      "loss tensor(2.2833, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1367)\n",
      "loss tensor(2.2885, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1035)\n",
      "loss tensor(2.2902, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1113)\n",
      "loss tensor(2.2826, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1191)\n",
      "loss tensor(2.2821, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1250)\n",
      "loss tensor(2.2748, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0918)\n",
      "loss tensor(2.2666, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1328)\n",
      "loss tensor(2.2929, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1133)\n",
      "loss tensor(2.2961, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0938)\n",
      "loss tensor(2.2860, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1016)\n",
      "loss tensor(2.2720, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1191)\n",
      "loss tensor(2.2711, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1270)\n",
      "loss tensor(2.2755, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1172)\n",
      "loss tensor(2.2692, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1230)\n",
      "loss tensor(2.2842, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1250)\n",
      "loss tensor(2.2613, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1387)\n",
      "loss tensor(2.2809, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1094)\n",
      "loss tensor(2.2784, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1309)\n",
      "loss tensor(2.2730, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1387)\n",
      "loss tensor(2.2789, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1074)\n",
      "loss tensor(2.2776, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1094)\n",
      "loss tensor(2.2703, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1309)\n",
      "loss tensor(2.2560, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1172)\n",
      "loss tensor(2.2721, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1309)\n",
      "loss tensor(2.2819, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1191)\n",
      "loss tensor(2.2819, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0859)\n",
      "loss tensor(2.2792, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1074)\n",
      "loss tensor(2.2649, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1094)\n",
      "loss tensor(2.2695, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1113)\n",
      "loss tensor(2.2650, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1094)\n",
      "loss tensor(2.2496, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1426)\n",
      "loss tensor(2.2899, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1250)\n",
      "loss tensor(2.2666, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1152)\n",
      "loss tensor(2.2541, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1113)\n",
      "loss tensor(2.2734, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1152)\n",
      "loss tensor(2.2725, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1289)\n",
      "loss tensor(2.2695, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1429)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5751b126ee4065a02b54328cc55f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 1:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(2.2666, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1191)\n",
      "loss tensor(2.2702, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1035)\n",
      "loss tensor(2.2863, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1055)\n",
      "loss tensor(2.2856, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1270)\n",
      "loss tensor(2.2913, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1035)\n",
      "loss tensor(2.2893, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0898)\n",
      "loss tensor(2.2766, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1230)\n",
      "loss tensor(2.2865, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1191)\n",
      "loss tensor(2.2751, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1074)\n",
      "loss tensor(2.2588, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1309)\n",
      "loss tensor(2.2583, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1055)\n",
      "loss tensor(2.2585, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1230)\n",
      "loss tensor(2.2865, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1055)\n",
      "loss tensor(2.2753, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1230)\n",
      "loss tensor(2.2458, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1211)\n",
      "loss tensor(2.2949, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0957)\n",
      "loss tensor(2.2535, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1387)\n",
      "loss tensor(2.2541, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1230)\n",
      "loss tensor(2.3010, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0996)\n",
      "loss tensor(2.2962, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1113)\n",
      "loss tensor(2.2810, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0996)\n",
      "loss tensor(2.2660, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1211)\n",
      "loss tensor(2.2641, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1270)\n",
      "loss tensor(2.2630, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1055)\n",
      "loss tensor(2.2705, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0996)\n",
      "loss tensor(2.2926, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0938)\n",
      "loss tensor(2.2536, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1348)\n",
      "loss tensor(2.2669, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1191)\n",
      "loss tensor(2.2678, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1230)\n",
      "loss tensor(2.2784, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0957)\n",
      "loss tensor(2.2785, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1367)\n",
      "loss tensor(2.2867, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1113)\n",
      "loss tensor(2.2927, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1523)\n",
      "loss tensor(2.2578, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.1113)\n",
      "loss tensor(2.2788, grad_fn=<NllLossBackward0>)\n",
      "percent correct tensor(0.0996)\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for inputs,labels in tqdm(train_dataloader, desc = f'epoch {epoch}'):\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        print(\"loss\",loss)\n",
    "        print(\"percent correct\", (outputs.argmax(dim=1)==labels).sum()/labels.size(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5f33c36-09c2-4e9a-a416-14b7a4755472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731a19ce34c445f4991f516e6af6c3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 0:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.5234)\n",
      "tensor(10.0586)\n",
      "tensor(10.0260)\n",
      "tensor(10.0098)\n",
      "tensor(10.1562)\n",
      "tensor(10.1562)\n",
      "tensor(10.3795)\n",
      "tensor(10.4736)\n",
      "tensor(10.4601)\n",
      "tensor(10.4688)\n",
      "tensor(10.3161)\n",
      "tensor(10.1725)\n",
      "tensor(10.1412)\n",
      "tensor(10.0167)\n",
      "tensor(9.9349)\n",
      "tensor(9.9976)\n",
      "tensor(9.9035)\n",
      "tensor(9.8741)\n",
      "tensor(9.9507)\n",
      "tensor(9.9500)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 0\n",
    "num_correct = 0 \n",
    "\n",
    "for inputs, labels in tqdm(test_dataloader, desc = f'epoch {epoch}'):\n",
    "    model.eval()\n",
    "    outputs = model(inputs)\n",
    "    outputs = outputs.argmax(dim=1)\n",
    "    num_samples += labels.size(0)\n",
    "    num_correct += (outputs == labels).sum()\n",
    "\n",
    "    print((num_correct / num_samples * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6e583-2d92-4dd6-bf95-685958128ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a565b63-d645-4c8e-b03e-822e54741bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51f9e6a1-8acb-4e3d-9b55-e01086df1819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2137,  1.8800, -0.6150, -4.0573],\n",
       "         [-2.1646,  1.7778, -0.6503, -3.9122],\n",
       "         [-2.1217,  1.6885, -0.6811, -3.7853]],\n",
       "\n",
       "        [[ 0.1410,  3.1941,  1.7682, -3.3440],\n",
       "         [ 0.1855,  3.1015,  1.7362, -3.2124],\n",
       "         [ 0.2231,  3.0232,  1.7091, -3.1012]]], grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self,d_model):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.key = nn.Linear(d_model,d_model)\n",
    "        self.query = nn.Linear(d_model,d_model)\n",
    "        self.value = nn.Linear(d_model,d_model)\n",
    "        self.softmax = nn.Softmax(dim=2) #along 3rd dimension, so the sum of similarities for a given query is 1\n",
    "\n",
    "    def forward(self,x):\n",
    "        #x.shape = [m batches, n words in a sequence, d_model features in a word (length of embedding)]\n",
    "        keys = self.key(x)\n",
    "        queries = self.query(x)\n",
    "        values = self.value(x)\n",
    "\n",
    "        scores = torch.matmul(queries, keys.transpose(1,2))/self.d_model**.5 #n x n\n",
    "        attention = self.softmax(scores)\n",
    "        weighted = torch.matmul(attention, values) #n x d_model , torch.bmm is batch matmul for 3 dim\n",
    "        return weighted\n",
    "\n",
    "\n",
    "attention = SelfAttention(d_model=4)\n",
    "x = torch.tensor([\n",
    "        [[1., 2., 3., 4.],\n",
    "         [2., 3., 4., 5.],\n",
    "         [3., 4., 5., 6.]],\n",
    "\n",
    "        [[4., 3., 2., 1.],\n",
    "         [5., 4., 3., 2.],\n",
    "         [6., 5., 4., 3.]]\n",
    "])\n",
    "weighted = attention.forward(x)\n",
    "weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd3d40b0-d8a4-4e60-9cc5-1bf0b12a30ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5894, -0.5033, -0.5218, -0.4477],\n",
       "         [-2.6329, -0.1831, -0.1079,  0.8398],\n",
       "         [-2.2823, -0.5435, -0.5072, -0.3413]],\n",
       "\n",
       "        [[-0.7238, -0.0269, -0.1612,  0.4117],\n",
       "         [-0.7842, -0.4719, -0.5143, -0.7158],\n",
       "         [-1.0875, -0.0605, -0.1583,  0.3944]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same computation overhead as self attention but more semantic representations\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, h):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % h == 0, \"d_k=d_v=d_model/h\"\n",
    "        self.h = h #num_heads\n",
    "        self.d_model = d_model #length of embeddings\n",
    "        self.d_k = self.d_v = int(self.d_model / self.h)\n",
    "        \n",
    "        # self.query = nn.Linear(d_model,d_model)\n",
    "        # self.key = nn.Linear(d_model,d_model)\n",
    "        # self.value = nn.Linear(d_model,d_model)\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model,d_model)\n",
    "        self.W_K = nn.Linear(d_model,d_model)\n",
    "        self.W_V = nn.Linear(d_model,d_model)\n",
    "\n",
    "        self.W_O = nn.Linear(d_model,d_model)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # def computeQKV(self,x):\n",
    "    #     batch_size, seq_length, d_model = x.size()\n",
    "    #     Q = self.query(x)\n",
    "    #     K = self.key(x)\n",
    "    #     V = self.value(x)\n",
    "    #     return Q,K,V\n",
    "        \n",
    "    def forward(self,Q,K,V):\n",
    "        batch_size, seq_length, d_model = Q.size()\n",
    "        \n",
    "        queries = self.W_Q(Q)\n",
    "        keys = self.W_K(K)\n",
    "        values = self.W_V(V)\n",
    "\n",
    "        queries = queries.reshape(batch_size, self.h, seq_length, self.d_k) #(batch size, seq_length, d_model) ==> (batch size, seq_length, h, d_k)\n",
    "        keys = keys.reshape(batch_size, self.h, seq_length, self.d_k)\n",
    "        values = values.reshape(batch_size, self.h, seq_length, self.d_v)\n",
    "\n",
    "        queries = queries.transpose(1,2) #(batch size, h, seq_length, d_k), flips the dims 1 and 2\n",
    "        keys = keys.transpose(1,2)\n",
    "        values = values.transpose(1,2)\n",
    "\n",
    "        scores = torch.matmul(queries, keys.transpose(-2,-1))/self.d_k**.5\n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "        weighted = torch.matmul(attention, values)\n",
    "        concat = weighted.reshape(batch_size, seq_length, d_model)\n",
    "        out = self.W_O(concat) #W_O\n",
    "        return out\n",
    "\n",
    "x = torch.tensor([\n",
    "        [[1., 2., 3., 4.],\n",
    "         [2., 3., 4., 5.],\n",
    "         [3., 4., 5., 6.]],\n",
    "\n",
    "        [[4., 3., 2., 1.],\n",
    "         [5., 4., 3., 2.],\n",
    "         [6., 5., 4., 3.]]\n",
    "])\n",
    "mha = MultiHeadAttention(d_model=4,h=2)\n",
    "Q,K,V = x,x,x\n",
    "# Q,K,V = mha.computeQKV(x), not needed because it is a double linear transformation so does the same thing X-->Q=WX-->W_Q*Q as X--> W_Q*X\n",
    "mha.forward(Q,K,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25843a4f-a386-4f76-abe7-2b8168560651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5914,  1.0629, -2.4170, -1.6738],\n",
       "         [-2.1618,  0.9891, -2.8905, -2.2325],\n",
       "         [-2.7321,  0.9153, -3.3640, -2.7912]],\n",
       "\n",
       "        [[-0.4519, -1.0591,  0.3878, -1.1029],\n",
       "         [-1.0222, -1.1328, -0.0857, -1.6616],\n",
       "         [-1.5925, -1.2066, -0.5592, -2.2203]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace8690-e0cd-4f99-a379-cda2e5b5bf3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
